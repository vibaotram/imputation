Usage: /usr/bin/STITCH [options]


Options:
	--K=K
		How many founder / mosaic haplotypes to use

	--S=S
		How many sets of founder / mosaic haplotypes to use [default 1] 

	--nGen=NGEN
		Number of generations since founding or mixing. Note that the algorithm is relatively robust to this. Use nGen = 4 * Ne / K if unsure

	--cramlist=CRAMLIST
		Path to file with cram file locations. File is one row per entry, path to cram files. cram files are converted to bam files on the fly for parsing into STITCH [default ""] 

	--sampleNames_file=SAMPLENAMES_FILE
		Optional, if not specified, sampleNames are taken from the SM tag in the header of the BAM / CRAM file. This argument is the path to file with sampleNames for samples. It is used directly to name samples in the order they appear in the bamlist / cramlist [default ""] 

	--reference=REFERENCE
		Path to reference fasta used for making cram files. Only required if cramlist is defined [default ""] 

	--genfile=GENFILE
		Path to gen file with high coverage results. Empty for no genfile. File has a header row with a name for each sample, matching what is found in the bam file. Each subject is then a tab seperated column, with 0 = hom ref, 1 = het, 2 = hom alt and NA indicating missing genotype, with rows corresponding to rows of the posfile. Note therefore this file has one more row than posfile which has no header [default ""] 

	--method=METHOD
		How to run imputation - either diploid, pseudoHaploid, or diploid-inbred. Please see main README for more information. All methods assume diploid samples. diploid is the most accurate but slowest, while pseudoHaploid may be advantageous for large sample sizes and K. diploid-inbred assumes all samples are inbred and invokes an internal haploid mathematical model but outputs diploid genotypes and probabilities [default diploid] 

	--output_format=OUTPUT_FORMAT
		one of bgvcf (i.e. bgziped VCF) or bgen (Layout = 2, CompressedSNPBlocks = 1) [default bgvcf] 

	--B_bit_prob=B_BIT_PROB
		when using bgen, how many bits to use to store each double. Optiosn are 8, 16, 24 or 32 [default 16] 

	--outputInputInVCFFormat=OUTPUTINPUTINVCFFORMAT
		Whether to output the input in vcf format [default FALSE] 

	--downsampleToCov=DOWNSAMPLETOCOV
		What coverage to downsample individual sites to. This ensures no floating point errors at sites with really high coverage [default 50] 

	--downsampleFraction=DOWNSAMPLEFRACTION
		Downsample BAMs by choosing a fraction of reads to retain. Must be value 0<downsampleFraction<1 [default 1] 

	--readAware=READAWARE
		Whether to run the algorithm is read aware mode. If false, then reads are split into new reads, one per SNP per read [default TRUE] 

	--chrStart=CHRSTART
		When loading from BAM, some start position, before SNPs occur. Default NA will infer this from either regionStart, regionEnd and buffer, or posfile [default NA] 

	--chrEnd=CHREND
		When loading from BAM, some end position, after SNPs occur. Default NA will infer this from either regionStart, regionEnd and buffer, or posfile [default NA] 

	--regionStart=REGIONSTART
		When running imputation, where to start from. The 1-based position x is kept if regionStart <= x <= regionEnd [default NA] 

	--regionEnd=REGIONEND
		When running imputation, where to stop. [default NA] 

	--buffer=BUFFER
		Buffer of region to perform imputation over. So imputation is run form regionStart-buffer to regionEnd+buffer, and reported for regionStart to regionEnd, including the bases of regionStart and regionEnd [default NA] 

	--maxDifferenceBetweenReads=MAXDIFFERENCEBETWEENREADS
		How much of a difference to allow the reads to make in the forward backward probability calculation. For example, if P(read | state 1)=1 and P(read | state 2)=1e-6, re-scale so that their ratio is this value. This helps prevent any individual read as having too much of an influence on state changes, helping prevent against influence by false positive SNPs [default 1000] 

	--maxEmissionMatrixDifference=MAXEMISSIONMATRIXDIFFERENCE
		Similar to maxDifferenceBetweenReads, specifies ratio of how much larger the most probable state can be than the least probable state, but across all reads rather than for a single read. This helps to limit overflow in C++ calculations [default 1e10] 

	--alphaMatThreshold=ALPHAMATTHRESHOLD
		Minimum (maximum is 1 minus this) state switching into probabilities [default 1e-4] 

	--emissionThreshold=EMISSIONTHRESHOLD
		Emission probability bounds. emissionThreshold < P(alt read | state k) < (1-emissionThreshold) [default 1e-4] 

	--iSizeUpperLimit=ISIZEUPPERLIMIT
		Do not use reads with an insert size of more than this value [default as.integer(600)] 

	--bqFilter=BQFILTER
		Minimum BQ for a SNP in a read. Also, the algorithm uses bq<=mq, so if mapping quality is less than this, the read isnt used [default as.integer(17)] 

	--niterations=NITERATIONS
		Number of EM iterations. [default 40] 

	--shuffleHaplotypeIterations=SHUFFLEHAPLOTYPEITERATIONS
		Iterations on which to perform heuristic attempt to shuffle founder haplotypes for better fit. To disable set to NA. [default c(4, 8, 12, 16)] 

	--splitReadIterations=SPLITREADITERATIONS
		Iterations to try and split reads which may span recombination breakpoints for a better fit [default 25] 

	--expRate=EXPRATE
		Expected recombination rate in cM/Mb [default 0.5] 

	--maxRate=MAXRATE
		Maximum recomb rate cM/Mb [default 100] 

	--minRate=MINRATE
		Minimum recomb rate cM/Mb [default 0.1] 

	--Jmax=JMAX
		Maximum number of SNPs on a read [default 1000] 

	--regenerateInput=REGENERATEINPUT
		Whether to regenerate input files. If this is FALSE, please using the same regionStart, regionEnd, buffer and posfile as you used to generate the input. Setting any of those to different values can cause the previous input data to be improperly interpreted. Please also see originalRegionName and regenerateInputWithDefaultValues [default TRUE] 

	--originalRegionName=ORIGINALREGIONNAME
		If regenerateInput is FALSE (i.e. using existing data), this is the name of the original region name (chr.regionStart.regionEnd). This is necessary to load past variables [default NA] 

	--keepInterimFiles=KEEPINTERIMFILES
		Whether to keep interim parameter estimates [default FALSE] 

	--keepTempDir=KEEPTEMPDIR
		Whether to keep files in temporary directory [default FALSE] 

	--switchModelIteration=SWITCHMODELITERATION
		Whether to switch from pseudoHaploid to diploid and at what iteration (NA for no switching) [default NA] 

	--generateInputOnly=GENERATEINPUTONLY
		Whether to just generate input data then quit [default FALSE] 

	--restartIterations=RESTARTITERATIONS
		In pseudoHaploid method, which iterations to look for collapsed haplotype prnobabilities to resolve [default NA] 

	--refillIterations=REFILLITERATIONS
		When to try and refill some of the less frequently used haplotypes [default c(6, 10, 14, 18)] 

	--downsampleSamples=DOWNSAMPLESAMPLES
		What fraction of samples to retain. Useful for checking effect of N on imputation. Not meant for general use [default 1] 

	--downsampleSamplesKeepList=DOWNSAMPLESAMPLESKEEPLIST
		When downsampling samples, specify a numeric list of samples to keep [default NA] 

	--subsetSNPsfile=SUBSETSNPSFILE
		If input data has already been made for a region, then subset down to a new set of SNPs, as given by this file. Not meant for general use [default NA] 

	--useSoftClippedBases=USESOFTCLIPPEDBASES
		Whether to use (TRUE) or not use (FALSE) bases in soft clipped portions of reads [default FALSE] 

	--outputBlockSize=OUTPUTBLOCKSIZE
		How many samples to write out to disk at the same time when making temporary VCFs that are later pasted together at the end to make the final VCF. Smaller means lower RAM footprint, larger means faster write. [default 1000] 

	--outputSNPBlockSize=OUTPUTSNPBLOCKSIZE
		How many SNPs to write to disk at one time to reduce RAM usage when making VCFs [default 10000] 

	--inputBundleBlockSize=INPUTBUNDLEBLOCKSIZE
		If NA, disable bundling of input files. If not NA, bundle together input files in sets of <= inputBundleBlockSize together [default NA] 

	--genetic_map_file=GENETIC_MAP_FILE
		Path to file with genetic map information, a file with 3 white-space delimited entries giving position (1-based), genetic rate map in cM/Mbp, and genetic map in cM [default ""] 

	--reference_haplotype_file=REFERENCE_HAPLOTYPE_FILE
		Path to reference haplotype file in IMPUTE format (file with no header and no rownames, one row per SNP, one column per reference haplotype, space separated, values must be 0 or 1) [default ""] 

	--reference_legend_file=REFERENCE_LEGEND_FILE
		Path to reference haplotype legend file in IMPUTE format (file with one row per SNP, and a header including position for the physical position in 1 based coordinates, a0 for the reference allele, and a1 for the alternate allele) [default ""] 

	--reference_sample_file=REFERENCE_SAMPLE_FILE
		Path to reference sample file (file with header, one must be POP, corresponding to populations that can be specified using reference_populations) [default ""] 

	--reference_populations=REFERENCE_POPULATIONS
		Vector with character populations to include from reference_sample_file e.g. CHB, CHS [default NA] 

	--reference_phred=REFERENCE_PHRED
		Phred scaled likelihood or an error of reference haplotype. Higher means more confidence in reference haplotype genotypes, lower means less confidence [default 20] 

	--reference_iterations=REFERENCE_ITERATIONS
		When using reference haplotypes, how many iterations to use to train the starting data [default 40] 

	--reference_shuffleHaplotypeIterations=REFERENCE_SHUFFLEHAPLOTYPEITERATIONS
		When using reference haplotypes, how much shuffling to do to lead to better global fit [default c(4, 8, 12, 16)] 

	--initial_min_hapProb=INITIAL_MIN_HAPPROB
		Initial lower bound for probability read comes from haplotype. Double bounded between 0 and 1 [default 0.2] 

	--initial_max_hapProb=INITIAL_MAX_HAPPROB
		Initial upper bound for probability read comes from haplotype. Double bounded between 0 and 1 [default 0.8] 

	--regenerateInputWithDefaultValues=REGENERATEINPUTWITHDEFAULTVALUES
		If regenerateInput is FALSE and the original input data was made using regionStart, regionEnd and buffer as default values, set this equal to TRUE [default FALSE] 

	--plotHapSumDuringIterations=PLOTHAPSUMDURINGITERATIONS
		Boolean TRUE/FALSE about whether to make a plot that shows the relative number of individuals using each ancestral haplotype in each iteration [default FALSE] 

	--plot_shuffle_haplotype_attempts=PLOT_SHUFFLE_HAPLOTYPE_ATTEMPTS
		Boolean TRUE/FALSE about whether to make a plot that tries to show the selection of ancestral haplotypes to check for shuffling / flipping [default FALSE] 

	--plotAfterImputation=PLOTAFTERIMPUTATION
		Boolean TRUE/FALSE about whether to make plots after imputation has run (can be set to FALSE if this throws errors on systems without x11) [default TRUE] 

	--save_sampleReadsInfo=SAVE_SAMPLEREADSINFO
		Experimental. Boolean TRUE/FALSE about whether to save additional information about the reads that were extracted [default FALSE] 

	--gridWindowSize=GRIDWINDOWSIZE
		Whether to work on a grid where reads are binned into windows of this size (1 based, i.e. first bin is bases 1-gridWindowSize). This is particularly appropriate for very low coverage data (e.g. less than 0.2X) and can substantially speed up analyses [default NA] 

	--shuffle_bin_nSNPs=SHUFFLE_BIN_NSNPS
		Parameter that controls how to detect ancestral haplotypes that are shuffled during EM for possible re-setting. If set (not NULL), then break per-SNP (or per-grid) every this many SNPs / grids, and compare each to detect whether haplotypes either 1) are more likely to stay where they are or 2) switch from one haplotype to another. Note that only one of shuffle_bin_nSNPs or shuffle_bin_radius should be non-NULL [default NULL] 

	--shuffle_bin_radius=SHUFFLE_BIN_RADIUS
		Parameter that controls how to detect ancestral haplotypes that are shuffled during EM for possible re-setting. If set (not NULL), then recombination rate is calculated around pairs of SNPs in window of twice this value, and those that exceed what should be the maximum (defined by nGen and maxRate) are checked for whether they are shuffled [default 5000] 

	--keepSampleReadsInRAM=KEEPSAMPLEREADSINRAM
		Whether to (generally) keep sampleReads in RAM or store them in the temporary directory. STITCH is substantially faster if this is FALSE at the expense of RAM [default FALSE] 

	--useTempdirWhileWriting=USETEMPDIRWHILEWRITING
		Whether to use temporary directory while writing output file (TRUE), or to keep result in RAM (FALSE). Using temporary directory is slower but uses less RAM [default FALSE] 

	--output_haplotype_dosages=OUTPUT_HAPLOTYPE_DOSAGES
		Whether to output ancestral haplotype dosages, i.e. the expected number of ancestral haplotypes carried by that sample at that locus [default FALSE] 

	--use_bx_tag=USE_BX_TAG
		Whether to try and use BX tag in same to indicate that reads come from the same underlying molecule [default TRUE] 

	--bxTagUpperLimit=BXTAGUPPERLIMIT
		When using BX tag, at what distance between reads to consider reads with the same BX tag to come from different molecules [default 50000] 
